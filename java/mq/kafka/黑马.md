# 第一章：kafka入门

## 1.简介

### 1.1.消息队列简介

#### 1.1.5.消息队列的两种模式

##### 1.1.5.1.点对点模式

> 消息发送者生产消息，发送到消息队列中，然后消息接收者从消息队列取出并且消费消息。消息被消费以后，消息队列中不在存储，所以消息接收者不可能消费到已经被消费的消息

点对点模式特点：

- 每个消息只有一个接收者（Consumer)，即一旦被消费，消息就不再在消息队列中
- 发送者和接收者之间没有依赖性，发送者发送消息之后，不管有没有接收者在运行，都不会影响发送者下次发送消息
- 接收者在成功接收消息之后需向队列应答成功，以便消息队列删除当前接受的消息

##### 1.1.5.2.发布订阅模式

发布/订阅模式特点：

- 每个消息可以有多个订阅者
- 发布者和订阅者之间有时间上的依赖性。针对某个主题（Topic）的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息
- 为了消费消息，订阅者需要提前订阅该角色主题，并保证在线运行

### 1.2.Kafka简介

#### 1.2.1.简介

Kafka是由Apache软件基金会开发的一个开源的流平台，由scala和Java编写。kafka的Apache官网是这样介绍kafka的

> Apache kafka是一个分布式流平台。一个分布式的流平台应该包含3点关键的能力
>
> 1. 发布和订阅数据流，类似于消息队列或者是企业消息传递系统
> 2. 以容错的持久化方式存储数据流
> 3. 处理数据流

#### 1.2.2.概念

1. Broker：kafka节点
2. Leader：用来处理消息的接受和消费等请求，也就是说producer是将消息push到leader，而consumer也是从leader上去poll消息
3. Follower：主要用于备份消息数据，一个leader会有多个follower
4. Topic：主题，用于承载消息
5. Partition：分区，用于主题分配存储（副本）
6. Consumer：消费者，从主题订阅消息的应用
7. Consumer Group：消费者组，由多个消费者组成

#### 1.2.2.kafka的应用场景

通常用在两类程序

1. 建立实时数据管道，以可靠地在系统或应用程序之间获取数据
2. 构建实时流应用程序，以转换或响应数据流

- Producers：可以有很多的应用程序，将消息数据放入到kafka集群中
- Consumers：可以有很多的应用程序，将消息数据从kafka集群中拉取出来
- Connectors：kafka的连接器可以将数据库中的数据导入到kafka，也可以将kafka的数据导出到数据库中
- Stream Processors：流处理器可以从kafka中拉取数据，也可以将数据写入到kafka中

#### 1.2.3.诞生背景

kafka的诞生，为了解决linkedin的数据管道问题，起初linkedin采用了ActiveMQ来进行数据交换，大约在2010前后，ActiveMQ还不能满足linkedin对数据传递系统的要求，经常由于各种缺陷导致消息阻塞或者服务无法正常访问，为了解决问题，linkedin自己研发了消息传递系统，

kafka、rabbitmq、rocketmq、activemq

### 1.3.kafka的优势

### 1.4.哪些公司在用

### 1.5.Kafka生态圈介绍

### 1.6.kafka版本

## 2.环境搭建

### 2.1.搭建kafka集群

安装 Kafka 在 CentOS 上可以分为几个主要步骤，包括下载 Kafka、配置和启动 ZooKeeper（Kafka 依赖的组件）、配置 Kafka 和启动 Kafka 服务。以下是基本的安装步骤：

#### 2.1.1. 安装 Java

首先确保你的系统上已经安装了 Java。Kafka 需要依赖 Java 运行环境。

```
sudo yum install java-1.8.0-openjdk-devel
```

#### 2.1.2. 下载并解压 Kafka

访问 Kafka 官网或者从 Apache 的镜像站点下载 Kafka：

```
wget https://mirrors.tuna.tsinghua.edu.cn/apache/kafka/3.1.0/kafka_2.13-3.1.0.tgz
```

解压 Kafka：

```
ar -xzf kafka_2.13-3.1.0.tgz
cd kafka_2.13-3.1.0
```

#### 2.1.3. 启动 ZooKeeper

Kafka 使用 ZooKeeper 来管理和协调集群中的节点。可以使用 Kafka 自带的脚本启动 ZooKeeper。在 Kafka 目录下执行：

```
bin/zookeeper-server-start.sh config/zookeeper.properties
```

#### 2.1.4. 配置 Kafka

复制默认配置文件并进行相应调整：

```
cp config/server.properties config/server.properties.bak
nano config/server.properties
```

确保以下配置正确（可以根据需要调整）：

- `broker.id`：每个 Kafka 服务器的唯一标识。
- `listeners`：Kafka 监听的连接端口，例如 `PLAINTEXT://:9092`。
- `log.dirs`：Kafka 存储日志文件的目录。

#### 2.1.5. 启动 Kafka 服务

使用以下命令启动 Kafka 服务：

```shell
bin/kafka-server-start.sh config/server.properties
```

#### 2.1.6. 验证安装

使用 Kafka 自带的命令行工具来创建主题并发送/接收消息，以验证 Kafka 是否正确运行：

- 创建一个名为 `test` 的主题：

  ```shell
  bin/kafka-topics.sh --create --topic test --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1
  ```

- 查看kafka中的主题

  ```shell
  bin/kafka-topics.sh --list --bootstrap-server 43.153.82.44:9092
  ```

  

- 发送消息到 `test` 主题：

  ```shell
  bin/kafka-console-producer.sh --topic test --bootstrap-server localhost:9092
  ```

- 在另一个终端接收消息：

  ```shell
  bin/kafka-console-consumer.sh --topic test --from-beginning --bootstrap-server localhost:9092
  ```

这些步骤应该可以帮助你在 CentOS 上安装并运行 Kafka。确保你的系统满足 Kafka 的依赖，并根据需要调整配置。

#### 2.1.7.集群环境

##### 2.1.7.1.多台服务器

##### 2.1.7.2.多端口启动

### 2.2.目录结构分析

### 2.3.kafka一键启动/关闭脚本

## 3.基础操作

### 3.1.创建topic

### 3.2.生产消息到kafka

### 3.3.从kafka消费消息

### 3.4.使用kafka Tools操作kafka

## 4.kafka基准测试

### 4.1.基准测试

## 5.Java编程操作kafka

### 5.1.同步生产消息到kafka中

### 5.2.从kafka的topic中消费消息

### 5.3.异步使用带有回调函数方法消息

## 6.架构

### 6.1.kafka需要概念

zookeeper集群，保存着kafka相关的一些元数据，使用kafkaToole工具可以浏览到

#### 6.1.1.Broker

- 一个kafka的集群通常由多个broker组成，这样才能实现负载均衡、以及容错
- broker是无状态（Stateless）的，它们是通过Zookeeper来维护集群状态
- 一个kafka的broker每秒可以处理数十万次读写，每个broker都可以处理TB消息而不影响性能

#### 6.1.2.zookeeper

- zk用来管理和协调broker，并且存储了kafka的元数据（例如：有多少topic、partition、consumer）

- zk服务主要用于通知生产者和消费者kafka集群中有新的broker加入、或者kafka集群中出现故障的broker

  > kafka正在逐步想办法将zookeeper剥离，维护两套集群成本较高，社区提出KIP-500就是要替换掉zookeeper的依赖，“kafka on	kafka” 自己来管理自己的**元数据**

#### 6.1.3.producer（生产者）

- 生产者负责将数据推送给broker的topic

#### 6.1.4.consumer（消费者）

- 消费者负责从broker的topic中拉取数据，并自己进行处理

#### 6.1.5.consumer group（消费者组）

- consumer group是kafka提供的可扩展且具有容错性的消费机制
- 一个消费者组可以包含多个消费者
- 一个消费者组有一个唯一的ID(group id)
- 组内的消费者一起消费主题的所有分区数据

#### 6.1.6.分区(partition)

- 在kafka集群中，主题被分为多个分区

#### 6.1.7.副本（Replicas）

- 副本可以确保某个服务器出现故障时，确保数据依然可以用

#### 6.1.8.主题（Topic）

- 主题是一个逻辑概念，用于生产发布数据，消费者拉取数据
- kafka中的主题必须要有标识符，而且是唯一的，kafka中可以有任意数量的主题，没有数量上限制
- 在主题中的消息是有结构的，一般一个主题包含一类消息
- 一单生产者发送消息到主题中，这些消息就不能被更新（更改）

#### 6.1.9.偏移量（offset）

- offset记录着下一条将要发送给Consumer的消息的序号
  - 默认kafkaoffset存储在zookeeper中
  - 在一个分区中，消息是有顺序的方式存储着，每个在分区的消费都是一个递增的id。这个就是偏移量offset
  - 偏移量在分区中是有意义的。在分区之间，offset是没有任何意义的

### 6.2.消费者组

kafka支持多个消费者同时消费一个主题中的数据。演示：启动两个消费者共同消费test主题的数据

1. 首先，修改生产者程序，让生产者每3秒生产1-100个数字。	

   ```java
   //3.发送1-100数字到Kafka的test主题中.
   while(true) {
   	for (int i=1;i<=100; ++i) {
   		// 注意：send方法是一个异步方法，它会将要发送的数据放入到一个buffer中，然后立即返回
   		// 这样可以让消息发送变得更高效。
   		producer.send(new ProducerRecord→("test", i +"");
   	}
   	Thread.sleep(3000);
    }
   
   ```

2. 同时运行两个消费者

- 一个消费者组中可以包含多个消费者，共同来消费topic中的数据
- 一个topic中如果只有一个分区，那么这个分区只能被某个组中的一个消费者消费
- 有多少分区，就可以被多少个组内消费者消费
- 设置test topic为2个分区
  - bin/kafka-topics.sh --zookeeper 127.0.0.1:2181 -alter --partitions 2 --topic test

## 7.kafka生产者幂等性与事务

### 7.1.幂等性

#### 	7.1.3.配置幂等性

```java
props.put("enable.idempotence", true);
```

为了实现**生产者**的幂等性，kafka引入了Producer ID（PID）和Sequence Number的概念。

- PID：每个Producer在初始化时，都会分配一个唯一的PID，这个PID对用户来说，是透明的。
- Sequence Number：针对每个生产者（对应PID）发送到指定主题分区的消息都对应一个从0开始递增的Sequence Number。

1. 生产者消息重复问题：
   1. kafka生产者生产消息到partition，如果直接发送消息，kafka会将消息保存到分区中，但kafka会返回一个ack给生产者，表示当前操作是否成功，是否已经保存了这条消息。如果ack响应的过程失败了，此时生产者会重试，继续发送没有发送成功的消息。kafka又会保存一条一模一样的消息
2. 在kafka中可以开启幂等性
   1. 当kafka的生产者生产消息时，会增加要给pid（生产者的唯一编号）和sequence number（针对消息的一个递增序列）
   2. 发送消息，会连着pid和sequence number一起发送
   3. kafka接收到消息，会将消息和pid、sequence number一并保存下来
   4. 如果ack响应失败，生产者重试，再次发送消息时，kafka会根据pid、sequence number是否需要在保存一条消息
   5. 判断条件：生产者发送过来的sequence number是否小于等于partition中消息对应的sequence number

### 7.2.kafka事务

### 7.3.【理解】kafka事务编程



# 第二章 Kafka高级

## 1.分区和副本机制

### 1.1.生产者分区写入策略

生产者写入消息到topic，kafka将依据不同的策略将数据分配到不同的分区中

1. 轮询分区策略
2. 随机分区策略
3. 按key分区分配策略
4. 自定义分区策略

#### 1.1.1.轮询策略

- 默认的策略，也是使用的最多的策略，可以最大限度保证所有消息平均分配到一个分区
- 如果生产消息时，key为null，则使用轮询算法均衡地分配分区

#### 1.1.2.随机策略（不用）

> 随机策略，每次都随机地将消息分配到每个分区。在较早的版本，默认的分区策略就是随机策略，也是为了将消息负载地写入到每个分区。但后续轮询策略表现更佳，所以基本上很少使用随机策略

#### 1.1.3.按key分配策略（key.hash取余方式）

> 按key分配策略，有可能出现【数据倾斜】，例如：某个key包含了大量的数据，因为key值一样，所以所有的数据都分配到一个分区中，造成该分区的消息数量远大于其他的分区

#### 1.1.4.乱序问题

> 轮询策略、随机策略都会导致一个问题，生产到kafka中的数据是乱序存储的。而安key分区可以一定程序上实现数据有序存储--也就是局部有序，但这又有可能导致数据倾斜，所以在实际生产环境中要结合实际情况来做取舍
>
> 当partition数量大于1，数据（消息）会打散分布在不同的partition中
>
> 只有一个分区，消息是有序的

#### 1.1.5.自定义分区策略

```java
public class KeyWithRandomPartitioner implements Partitioner{
    private Random r;
    
    @Override
    public void configure(Map<String, ?> configs){
        r = new Random();
    }
    
    @Override
    public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster){
        return r.nextInt(1000)%;
    }
}
```

### 1.2.消费者组Rebalance机制

#### 1.2.1.Rebalance在均衡

kafka中的Rebalance称之为在均衡，是kafka中确保Consumer group下所有的consumer如何达成一致，分配订阅的topic的每个分区的机制

Rebalance触发的时机有：

1. 消费者组中consumer的个数发生变化。例如有新的consumer加入到消费者组，或者是某个consumer停止了

2. 订阅的topic个数发生变化

   > 消费者可以订阅多个主题，假设当前的消费者组订阅了三个主题，但有一个主题突然被删除了，此时也需要再发生再均衡

3. 订阅的topic分区数发生变化

   1. 删除partition
   2. 新增partition

#### 1.2.2.Rebalance的不良影响

- 发生Rebalance时，consumer group下的所有consumer都会协调在一起共同参与，kafka使用分配策略尽可能达到最公平的分配

- Rebalance过程对consumer group产生非常严重的影响，Rebalance的过程中所有消费者停止工作，直到Rebalance完成，直到每个消费者都已经成功分配到所需要消费的分区为止

  再均衡：在某些情况下，消费者组中的消费者消费的分区会产生变化，会导致消费者分配不均匀（例如：有两个消费这消费三个，因为某个partition崩溃了，还有一个消费者当前没有分区要削峰），kafka consumer group就会启用rebalance机制，重新平衡这个consumer group内的消费者消费的分区分配

1.3.消费者分区分配策略



## 2.高级（High Level）API与低级（Low Level）API

## 3.监控工具kafka-eagle介绍

> 早期，要监控Kafka集群我们可以使用Kafka Monitor以及Kafka Manager，但随着我们对监控的功能要求、性能要求的提高，这些工具已经无法满足。
>
> ​	Kafka Eagle是一款结合了目前大数据Kafka监控工具的特点,重新研发的一块开源免费的Kafka集群优秀的监控工具。
> 它可以非常方便的监控生产环境中的offset、 lag变化、partition分布、owner等。
>
> 官网地址：https://www.kafka-eagle.org/

### 3.1.安装Kafka-Eagle

#### 3.1.1.开启kafa-eagle

3.2.1.JMX接口



## 4.kafka原理

## 5.kafka中数据清理（Log Deletion）

## 6.kafka配额限速机制

# 注意事项

## 1.版本

从 **Apache Kafka 2.8.0** 版本开始，引入了一种称为 KRaft 的新的内置存储架构，用于替代传统的 ZooKeeper，作为 Kafka 的元数据存储解决方案。这意味着在 Kafka 2.8.0 及更高版本中，可以选择使用 KRaft 来管理 Kafka 的元数据，而不再需要单独安装和运行外部的 ZooKeeper。

使用 KRaft 的优势包括：

1. **简化部署**：不再需要单独管理和维护 ZooKeeper 集群，减少了运维成本和复杂性。
2. **提高可靠性**：KRaft 作为 Kafka 内置的元数据存储，与 Kafka 服务紧密集成，有助于提高整体的可靠性和性能。

尽管 Kafka 2.8.0 提供了使用 KRaft 替代 ZooKeeper 的选项，但仍然可以选择继续使用传统的 ZooKeeper 作为 Kafka 的元数据存储。具体选择取决于你的部署需求和实际情况。

如果你使用的是 Kafka 2.8.0 或更新版本，并且想要尝试使用 KRaft，请确保在配置文件中正确配置相关属性，并且理解如何管理和维护 KRaft 所需的元数据

## 2.启动服务

### 2.1.创建kafka用户

### 2.2.创建kafka分组

```shell
[Unit]
Description=Apache Kafka
Documentation=http://kafka.apache.org/documentation.html
After=network.target

[Service]
Type=simple
User=kafka
Group=kafka

#Environment="JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64"

ExecStart=/opt/install/kafka/kafka_2.12-3.7.1/bin/kafka-server-start.sh /opt/install/kafka/kafka_2.12-3.7.1/config/server.properties
ExecStop=/opt/install/kafka/kafka_2.12-3.7.1/bin/kafka-server-stop.sh
Restart=on-abnormal
RestartSec=10
 
[Install]
WantedBy=multi-user.target


# 定义JAVA_HOME到kafka-run-class.sh
# 第一行
#export JAVA_HOME=/usr/local/jdk/jdk1.8.0_221
#export PATH=$PATH:$JAVA_HOME/bin

```

**[Unit] 部分：**

- `Description`: 描述服务的信息。
- `Documentation`: 提供服务文档的 URL。
- `Requires`, `Wants`, `After`, `Before` 等：定义了服务的依赖关系和启动顺序。

**[Service] 部分：**

- `Type`: 指定服务的类型，如 `simple`、`forking`、`oneshot` 等。
  - simple：这是最常见的服务类型。`simple` 表示服务的主进程将由 ExecStart 指定的命令启动，并且 systemd 将认为服务一直运行到进程退出或被杀死
  - forking：如果服务以 `forking` 类型启动，systemd 期望主进程会 fork 一个子进程出来。systemd 将等待主进程退出，并且会认为服务在主进程退出后结束。通常需要通过 `PIDFile` 参数指定主进程的 PID 文件位置，以便 systemd 能够追踪主进程的生命周期
  - oneshot：`oneshot` 类型的服务将在启动时运行一次指定的命令或脚本，并在命令完成后退出。这种服务通常不会常驻后台运行，而是用于执行一次性任务
  - dbus：`dbus` 类型的服务是通过 D-Bus 控制总线提供的服务。这种服务通常由 D-Bus 激活，并且 systemd 将等待 D-Bus 通知来启动或停止服务
  - notify：`notify` 类型的服务将会在启动时通知 systemd，主进程已准备就绪。通常需要在服务启动完成后发送一个信号给 systemd，如使用 `sd_notify()` 函数
  - `idle` 类型的服务会等待主进程变为空闲状态（即没有挂起的任务），然后 systemd 才会认为服务已经启动完成
  - `exec` 类型的服务会在服务的主进程退出时自动重启。这种类型的服务通常不需要主动指定 `ExecStart`，而是在服务退出时重新执行
- `ExecStart`: 指定启动服务时执行的命令或脚本。
- `ExecStop`: 指定停止服务时执行的命令或脚本。
- `User`, `Group`: 指定服务运行的用户和组。
- `Environment`: 设置环境变量。
- `Restart`: 定义服务在退出时的重新启动策略。
  - no 不重新启动服务。这是默认值，表示服务不会在退出时自动重启
  - always 无论服务何时退出，systemd 都会尝试重新启动它。这包括正常退出（例如通过 kill 命令）和非正常退出（例如程序崩溃）
  - on-success 只有在服务以退出状态码为 0 正常退出时才会自动重启
  - on-failure 只有在服务以非零状态码退出（即失败）时才会自动重启
  - on-abnormal 在服务以非正常方式退出（除了使用 kill 之外的方式，如段错误）时自动重启
  - on-abort 在服务因为调用 systemctl abort 而退出时自动重启

**[Install] 部分：**

- `WantedBy`, `RequiredBy`: 指定了哪些系统目标（targets）会启用此服务单元。

### 2.3.开机自启

```shell
sudo systemctl daemon-reload
```

## 3.应用场景

Java 消息队列（Message Queue, MQ）在分布式系统中扮演着重要角色，能够实现异步通信、解耦组件、提高系统可扩展性和可靠性。以下是 Java 消息队列的一些常见使用场景：

### 3.1. **异步处理**

- **场景描述**：在某些任务中，执行时间较长的操作可以放到后台处理，避免阻塞用户请求。
- **示例**：用户提交一个需要长时间处理的请求（如文件上传、数据处理等），系统将任务推送到消息队列中，由后台服务异步处理，并在完成后通知用户。
- **优点**：用户请求无需等待长时间任务完成，提升了系统的响应性。

### 3.2. **解耦系统组件**

- **场景描述**：在微服务架构或分布式系统中，多个服务可能需要交换信息。如果系统直接调用会耦合度过高，影响可维护性和扩展性。
- **示例**：订单服务和库存服务之间可以通过消息队列传递信息。当用户创建订单时，订单服务将订单信息放入消息队列，库存服务从队列中获取订单信息并更新库存。
- **优点**：服务之间松耦合，增强系统的可扩展性和容错能力。

### 3.3. **负载均衡**

- **场景描述**：多个消费者（消费者是处理消息的程序）可以从消息队列中并发地消费任务，从而实现负载均衡。
- **示例**：多个消费者监听同一个队列，分摊消息的处理压力。当消息队列中有新的任务时，消费者从队列中拉取并处理任务，避免单个消费者过载。
- **优点**：平衡多个消费者的负载，提高系统的处理能力和吞吐量。

### 3.4. **流量削峰**

- **场景描述**：系统在高峰时段会收到大量请求，可能导致资源过载或响应延迟。使用消息队列可以平滑请求的处理负载，避免短时间内过多请求冲击系统。
- **示例**：电商网站的秒杀活动或大促销时段，用户会在短时间内发送大量订单请求。通过消息队列，将这些请求按顺序处理，避免系统崩溃。
- **优点**：系统能够有效地应对流量高峰，确保不会因为突发流量导致系统宕机。

### 3.5. **事件驱动架构**

- **场景描述**：消息队列可以用于实现事件驱动架构（EDA）。当某些事件发生时，相关的服务可以被异步通知进行相应的处理。
- **示例**：当用户注册成功后，系统会触发“用户注册成功”事件，消息队列将该事件发布出去，其他服务（如邮件服务、消息通知服务等）可以根据事件类型做出响应。
- **优点**：实现松耦合的事件通知机制，易于扩展和维护。

### 3.6. **任务调度和定时任务**

- **场景描述**：使用消息队列来处理定时任务和延迟任务。在消息队列中，可以指定消息的延迟时间，或者定时发送消息。
- **示例**：某些定期任务（如每天的库存更新、数据同步等）可以通过消息队列按时触发，消息队列可以保证任务按时被处理。
- **优点**：简化了定时任务管理，通过队列控制任务的执行时间，避免了定时任务的复杂性。

### 3.7. **数据同步和跨系统通信**

- **场景描述**：在多个系统之间进行数据同步时，可以使用消息队列来确保数据一致性和异步传输。
- **示例**：在电商平台，订单信息、支付信息可能需要同步到多个系统（如订单服务、库存服务、财务服务等）。消息队列可以保证各个系统异步接收到相应数据。
- **优点**：保证系统间数据传递的可靠性和顺序性，同时避免因系统间直接调用而导致的高耦合。

### 3.8. **任务队列与工作流处理**

- **场景描述**：在需要多个步骤或多个服务参与的任务处理中，消息队列能够有效地处理任务流转和任务分配。
- **示例**：一个文件处理系统，首先将文件上传到系统，然后通过消息队列将文件的处理任务发送到不同的消费者，完成预处理、数据清洗、格式转换等步骤，最终将结果返回给用户。
- **优点**：支持复杂的任务流转和并发处理，提升系统的效率和可扩展性。

### 3.9. **消息队列用于异步通知**

- **场景描述**：通过消息队列来实现异步通知，比如发送用户短信通知、推送通知等。
- **示例**：用户注册成功后，系统通过消息队列发送通知到短信服务，短信服务再发送确认短信给用户。通过消息队列，保证了短信服务的异步处理，并且如果短信服务暂时不可用，消息会在队列中等待。
- **优点**：提高系统的异步性和容错性，避免短信服务等外部依赖的失败影响系统的主业务逻辑。

### 3.10. **缓存更新**

- **场景描述**：系统中可能有多个缓存存储（如 Redis、Memcached），当某些数据更新时，可以通过消息队列来同步缓存的更新。
- **示例**：用户修改了个人资料，系统通过消息队列通知缓存服务，缓存需要更新。
- **优点**：通过消息队列可以使缓存的更新更加灵活和高效。
